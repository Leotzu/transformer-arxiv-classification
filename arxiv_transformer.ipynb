{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNhNoJC6+GX4Yti1/cglc1e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leotzu/transformer-arxiv-classification/blob/main/arxiv_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1)** Setup environment and give your notebook access to google drive"
      ],
      "metadata": {
        "id": "llz5UX_RtJtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7STYBBI62Wr"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "!pip install torch pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive to access json file and save/load models and vocab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgdnXjeF8p9i",
        "outputId": "43ddac34-3cf2-4ec4-d156-259ed32308cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ciQPKDMi7n2Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2)** Define your model and functions for data loading and preprocessing\n",
        "\n",
        "- In Config, make sure to change the *project_dir* and *data_path* to where you have this project in your drive and where the json arXiv data is stored.\n",
        "\n",
        "- Change *prefix* to differentiate this training run from any others you do (it will be added to the beginning of every model, checkpoint, and vocab file saved during preprocessing and training)"
      ],
      "metadata": {
        "id": "iHnz9flOtIjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # define project directories\n",
        "    project_dir = '/content/drive/MyDrive/your_project_path'\n",
        "    data_path = project_dir + '/data/arxiv-metadata-oai-snapshot.json'\n",
        "    models_path = project_dir + '/models'\n",
        "    vocab_path = project_dir + '/vocab'\n",
        "    # this prefix will go infront of all the saved models, checkpoints, vocab, etc to differential between training sessions\n",
        "    prefix = '50k'\n",
        "\n",
        "    # data points (number of abstracts)\n",
        "    num_data_points = 50000\n",
        "\n",
        "    # model hyperparameters\n",
        "    d_model = 256\n",
        "    nhead = 8\n",
        "    num_encoder_layers = 3\n",
        "    num_decoder_layers = 3\n",
        "    dim_feedforward = 1024\n",
        "    max_seq_length = 256\n",
        "    batch_size = 64\n",
        "    learning_rate = 0.001\n",
        "    dropout_rate = 0.3\n",
        "    num_epochs = 30\n"
      ],
      "metadata": {
        "id": "Dbfcp-aB7oFO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.stoi = {\"<pad>\": 0, \"<unk>\": 1, \"<eos>\": 2}\n",
        "        self.itos = {0: \"<pad>\", 1: \"<unk>\", 2: \"<eos>\"}\n",
        "\n",
        "    def build_vocab(self, texts, min_freq=2):\n",
        "        counter = {}\n",
        "        for text in texts:\n",
        "            for word in text.split():\n",
        "                if word not in counter:\n",
        "                    counter[word] = 0\n",
        "                counter[word] += 1\n",
        "        idx = len(self.stoi)\n",
        "        for word, count in counter.items():\n",
        "            if count >= min_freq:\n",
        "                self.stoi[word] = idx\n",
        "                self.itos[idx] = word\n",
        "                idx += 1\n",
        "\n",
        "class ArxivDataset(Dataset):\n",
        "    def __init__(self, abstracts, vocab):\n",
        "        self.vocab = vocab\n",
        "        self.data = [self.vectorize(text) for text in abstracts]\n",
        "\n",
        "    def vectorize(self, text):\n",
        "        tokens = [self.vocab.stoi.get(word, self.vocab.stoi['<unk>']) for word in text.split()]\n",
        "        # Append <eos> token at the end of each abstract\n",
        "        tokens.append(self.vocab.stoi['<eos>'])\n",
        "        if len(tokens) > Config.max_seq_length:\n",
        "            tokens = tokens[:Config.max_seq_length]\n",
        "        else:\n",
        "            tokens += [self.vocab.stoi['<pad>']] * (Config.max_seq_length - len(tokens))\n",
        "        return torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return item[:-1], item[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "# Pad sequences to ensure each tensor is equal in size\n",
        "def collate_batch(batch):\n",
        "    # Separate source and target sequences\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    # Pad the sequences in the batch\n",
        "    src_batch_padded = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    tgt_batch_padded = pad_sequence(tgt_batch, padding_value=0, batch_first=True)\n",
        "\n",
        "    return src_batch_padded, tgt_batch_padded\n",
        "\n",
        "def load_data(file_path, num_rows=Config.num_data_points, split_ratio=0.8):\n",
        "    np.random.seed(5)\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        total_rows = sum(1 for line in file)\n",
        "    indices_to_keep = np.random.choice(range(total_rows), num_rows, replace=False)\n",
        "\n",
        "    train_idx = int(len(indices_to_keep) * split_ratio)\n",
        "    train_indices = set(indices_to_keep[:train_idx])\n",
        "    test_indices = set(indices_to_keep[train_idx:])\n",
        "\n",
        "    train_abstracts = []\n",
        "    test_abstracts = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for i, line in enumerate(file):\n",
        "            if i in train_indices:\n",
        "                data_line = json.loads(line)\n",
        "                if 'abstract' in data_line:\n",
        "                    abstract = data_line['abstract'].strip()\n",
        "                    train_abstracts.append(abstract)\n",
        "            elif i in test_indices:\n",
        "                data_line = json.loads(line)\n",
        "                if 'abstract' in data_line:\n",
        "                    abstract = data_line['abstract'].strip()\n",
        "                    test_abstracts.append(abstract)\n",
        "    return train_abstracts, test_abstracts\n",
        "\n",
        "def get_data():\n",
        "    train_abstracts, test_abstracts = load_data(Config.data_path)\n",
        "    vocab = Vocabulary()\n",
        "    vocab.build_vocab(train_abstracts + test_abstracts)  # Build vocab using both to ensure consistency\n",
        "\n",
        "    train_dataset = ArxivDataset(train_abstracts, vocab)\n",
        "    test_dataset = ArxivDataset(test_abstracts, vocab)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "    return train_loader, test_loader, vocab"
      ],
      "metadata": {
        "id": "T7uON64s7o_3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length, dropout_rate):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(max_seq_length, d_model))\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout=dropout_rate)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.embedding(src) + self.positional_encoding[:src.size(1), :]\n",
        "        tgt = self.embedding(tgt) + self.positional_encoding[:tgt.size(1), :]\n",
        "        output = self.transformer(src, tgt)\n",
        "        return self.fc_out(output)"
      ],
      "metadata": {
        "id": "_F0-DLou7pcr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3)** Train the model\n",
        "\n",
        "- This function will save your models and checkpoints to model_path after each epoch, as well as the history of losses and dataloader for later evaluation"
      ],
      "metadata": {
        "id": "tNpRd9TOzDmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    train_loader, test_loader, vocab = get_data()\n",
        "    # save vocab for later use during evaluation inference\n",
        "    with open(Config.vocab_path + f'/{Config.prefix}_vocab.pkl', 'wb') as f:\n",
        "        pickle.dump(vocab, f)\n",
        "    # define model\n",
        "    model = TransformerModel(\n",
        "        vocab_size=len(vocab.stoi),\n",
        "        d_model=Config.d_model,\n",
        "        nhead=Config.nhead,\n",
        "        num_encoder_layers=Config.num_encoder_layers,\n",
        "        num_decoder_layers=Config.num_decoder_layers,\n",
        "        dim_feedforward=Config.dim_feedforward,\n",
        "        max_seq_length=Config.max_seq_length,\n",
        "        dropout_rate=Config.dropout_rate\n",
        "    ).to('cuda')\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=Config.learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=vocab.stoi['<pad>'])\n",
        "\n",
        "    # Variables to save for evaluation\n",
        "    training_losses = []\n",
        "    testing_losses = []\n",
        "\n",
        "    print(\"training started...\")\n",
        "    for epoch in range(Config.num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for src, tgt in train_loader:\n",
        "            src, tgt = src.to('cuda'), tgt.to('cuda')\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt)\n",
        "            loss = criterion(output.view(-1, len(vocab.stoi)), tgt.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Loss {loss.item()}')\n",
        "\n",
        "        # Calculate average losses for the epoch\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        training_losses.append(avg_train_loss)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        model.eval()\n",
        "        total_test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for src, tgt in test_loader:\n",
        "                src, tgt = src.to('cuda'), tgt.to('cuda')\n",
        "                output = model(src, tgt)\n",
        "                loss = criterion(output.view(-1, len(vocab.stoi)), tgt.view(-1))\n",
        "                total_test_loss += loss.item()\n",
        "        avg_test_loss = total_test_loss / len(test_loader)\n",
        "        testing_losses.append(avg_test_loss)\n",
        "\n",
        "        # Save the model and checkpoint\n",
        "        model_save_path = f'{Config.models_path}/{Config.prefix}_model_epoch_{epoch+1}.pth'\n",
        "        checkpoint_path = f'{Config.models_path}/{Config.prefix}_checkpoint_epoch_{epoch+1}.pth'\n",
        "        save_model(model, model_save_path)\n",
        "        save_checkpoint(model, optimizer, epoch, checkpoint_path)\n",
        "\n",
        "    # Save losses and dataloader for evaluation\n",
        "    torch.save({\n",
        "        'training_losses': training_losses,\n",
        "        'testing_losses': testing_losses,\n",
        "        'model': model.state_dict(),\n",
        "        'vocab': vocab,\n",
        "        'criterion': criterion\n",
        "    }, f'{Config.models_path}/{Config.prefix}_evaluation_data.pth')\n",
        "\n",
        "def save_model(model, filename):\n",
        "    torch.save(model.state_dict(), filename)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, filepath):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, filepath)\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "id": "AiShbx21Dd3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4)** Evaluate the training of your model and perform inference in generate_text to create new abstracts from a prompt"
      ],
      "metadata": {
        "id": "bNurE-9TzdOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "    # Load saved training and testing data\n",
        "    data = torch.load(f'{Config.models_path}/{Config.prefix}_evaluation_data.pth') # Change to a different model name if needed. This evalutes last trained model by default\n",
        "    training_losses = data['training_losses']\n",
        "    testing_losses = data['testing_losses']\n",
        "\n",
        "    plt.plot(training_losses, label='Training Loss')\n",
        "    plt.plot(testing_losses, label='Testing Loss', linestyle='--')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Testing Losses Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "evaluate()"
      ],
      "metadata": {
        "id": "7LVV-MDrT9AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, vocab_path, model_path, top_k=5, max_output_length=50):\n",
        "    with open(vocab_path, 'rb') as f:\n",
        "        vocab = pickle.load(f)\n",
        "\n",
        "    model = TransformerModel(\n",
        "        vocab_size=len(vocab.stoi),\n",
        "        d_model=Config.d_model,\n",
        "        nhead=Config.nhead,\n",
        "        num_encoder_layers=Config.num_encoder_layers,\n",
        "        num_decoder_layers=Config.num_decoder_layers,\n",
        "        dim_feedforward=Config.dim_feedforward,\n",
        "        max_seq_length=Config.max_seq_length,\n",
        "        dropout_rate=Config.dropout_rate\n",
        "    ).to('cuda')\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    tokens = [vocab.stoi.get(word, vocab.stoi['<unk>']) for word in prompt.split()]\n",
        "    input_tensor = torch.tensor([tokens], dtype=torch.long).to('cuda')\n",
        "    generated_tokens = tokens[:]\n",
        "\n",
        "    while len(generated_tokens) < max_output_length:\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor, input_tensor)\n",
        "            logits = output[:, -1, :]  # Focus only on the last output token's logits\n",
        "            values, indices = torch.topk(logits, top_k)\n",
        "            probabilities = F.softmax(values, dim=-1)\n",
        "            next_token_index = torch.multinomial(probabilities, 1).item()  # Get scalar index\n",
        "            next_token = indices[0][next_token_index].item()  # Access the corresponding token index\n",
        "\n",
        "        if next_token == vocab.stoi['<eos>']:\n",
        "            break\n",
        "\n",
        "        generated_tokens.append(next_token)\n",
        "        input_tensor = torch.tensor([generated_tokens], dtype=torch.long).to('cuda')  # Update input for next prediction\n",
        "\n",
        "    generated_text = ' '.join(vocab.itos[token] for token in generated_tokens if token not in (vocab.stoi['<eos>'], vocab.stoi['<pad>']))\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "prompt = 'due to destructive interference between different paths for' # Enter custom prompt\n",
        "vocab_path = Config.vocab_path + f'/{Config.prefix}_vocab.pkl'\n",
        "model_path = Config.models_path + f'/{Config.prefix}_model_epoch_30.pth' # NOTE: ensure the latest model epoch is being used\n",
        "print(f'vocab_path: {vocab_path}')\n",
        "print(f'model_path: {model_path}')\n",
        "print('Model output:')\n",
        "print(generate_text(prompt, vocab_path, model_path, max_output_length=50))"
      ],
      "metadata": {
        "id": "4WCU8iuG7psY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to load the model you've trained and finetune it on a new dataset that determines whether an abstract is AI-related or not. This is done in a different notebook, titled ***finetuned_classifier.ipynb***"
      ],
      "metadata": {
        "id": "DwuxILxB0Y-c"
      }
    }
  ]
}